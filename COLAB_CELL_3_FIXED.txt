===============================================================================
CELL 3: Download Model (FIXED VERSION)
===============================================================================
Copy and paste THIS version into your Colab notebook Cell 3:

---START COPYING HERE---

import os
MODEL_FILE = "Mistral-7B-Instruct-v0.3.Q4_K_M.gguf"
MODEL_URL = "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf"

if not os.path.exists(MODEL_FILE):
    print(f"üì• Downloading {MODEL_FILE}...")
    print("‚è±Ô∏è  This will take about 2 minutes (4.37 GB)\n")
    
    # Download with wget (shows progress)
    !wget --show-progress {MODEL_URL}
    
    # Verify download succeeded
    if os.path.exists(MODEL_FILE):
        file_size = os.path.getsize(MODEL_FILE) / 1024**3
        print(f"\n‚úÖ Download complete! Size: {file_size:.2f} GB")
    else:
        print("\n‚ùå wget failed. Trying curl...")
        !curl -L -o {MODEL_FILE} {MODEL_URL}
        
        if os.path.exists(MODEL_FILE):
            file_size = os.path.getsize(MODEL_FILE) / 1024**3
            print(f"\n‚úÖ Downloaded with curl! Size: {file_size:.2f} GB")
        else:
            print("\n‚ùå Download failed!")
            print("Manual download:")
            print(f"1. Click: {MODEL_URL}")
            print(f"2. Upload to Colab")
else:
    file_size = os.path.getsize(MODEL_FILE) / 1024**3
    print(f"‚úÖ Model already exists! Size: {file_size:.2f} GB")

print("\nüí° Model ready for GPU inference!")

---STOP COPYING HERE---

===============================================================================
WHAT THIS DOES:
===============================================================================

1. Checks if model file exists
2. Downloads with wget (shows progress bar)
3. Verifies download succeeded
4. If wget fails, tries curl as backup
5. Shows file size when done

Expected output:
üì• Downloading Mistral-7B-Instruct-v0.3.Q4_K_M.gguf...
‚è±Ô∏è  This will take about 2 minutes (4.37 GB)
[Progress bar shown]
‚úÖ Download complete! Size: 4.37 GB
üí° Model ready for GPU inference!

===============================================================================
IF DOWNLOAD STILL FAILS:
===============================================================================

Alternative Method - Direct Upload:

1. Download model to your Mac first:
   Open in browser: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf

2. Wait for 4.37 GB download

3. In Colab, click folder icon (left sidebar)

4. Click upload icon

5. Select the downloaded .gguf file

6. Wait for upload to Colab

7. Then run Cell 4 onwards

Note: This takes longer but is more reliable if Colab has network issues.

===============================================================================
