# GPU-optimized requirements for NVIDIA CUDA
# Install these on your NVIDIA GPU machine (Windows/Linux/Cloud)

# Core LLM and LangChain
llama-cpp-python  # Will be reinstalled with CUDA support
langchain>=0.1.0
langchain-core>=0.1.0
langchain-community>=0.0.10

# Caching
redis>=5.0.0

# Pinecone Vector Database
pinecone-client>=5.0.0

# PyTorch with CUDA support
# Install separately with: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
torch>=2.0.0
torchvision
torchaudio

# Embeddings and Transformers
sentence-transformers>=2.2.0
transformers>=4.30.0
accelerate>=0.20.0

# Additional ML tools
scikit-learn>=1.3.0
numpy>=1.24.0
scipy>=1.10.0

# Optimization libraries
bitsandbytes>=0.41.0  # For 8-bit quantization
optimum>=1.12.0  # Hugging Face optimization toolkit

# Monitoring and utilities
nvidia-ml-py3>=7.352.0  # NVIDIA GPU monitoring
gpustat>=1.0.0  # Easy GPU stats
psutil>=5.9.0  # System monitoring

# Optional: For better performance
xformers>=0.0.20  # Memory-efficient attention
flash-attn>=2.0.0  # Flash attention (requires CUDA 11.6+)

# Development tools
ipython>=8.12.0
jupyter>=1.0.0
notebook>=6.5.0

# Data handling
pandas>=2.0.0
